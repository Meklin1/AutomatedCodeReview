{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Code review comment augmentation for training and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bv2PqbDAZAAm"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import concurrent.futures\n",
        "import json\n",
        "import os\n",
        "import requests\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')\n",
        "DEEPSEEK_API_URL = \"https://api.deepseek.com/chat/completions\"\n",
        "DEEPSEEK_MODEL_ID = \"deepseek-chat\"\n",
        "\n",
        "DATA_PATH   = \"train-java-with-code-with-pmd.json\" # or valid-java-with-code-with-pmd.json.\n",
        "OUTPUT_PATH = \"train_final.jsonl\" # or valid_final.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Teacher prompt to augment and filter real code review comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpcAevS0aPlO"
      },
      "outputs": [],
      "source": [
        "def construct_teacher_prompt_messages(patch, real_human_review, pmd_warnings, patched_code):\n",
        "    system_prompt_teacher = \"\"\"\n",
        "    You are a Java Code-Review Assistant. You’ll be given:\n",
        "\n",
        "    1.  A Code Patch (Diff)\n",
        "    2.  An optional Review Comment (from a human reviewer)\n",
        "    3.  Optional Static Analysis Warnings\n",
        "    4.  The Final Patched Code\n",
        "\n",
        "    **Core Objective:** Your primary role is to identify and help address **actual code defects**. A code defect is an issue that negatively impacts code correctness, robustness, performance, security, or represents a significant deviation from essential programming best practices. Focus exclusively on these defects.\n",
        "\n",
        "    **Guidelines for All Comments & Analysis:**\n",
        "    * **Defect-Centric:** All feedback must target a specific code defect. Do not comment on purely stylistic preferences or generic observations.\n",
        "    * **Static Analysis Warnings:**\n",
        "        * A warning is relevant *only if* it directly pertains to changed lines AND clearly indicates a **code defect** as defined above.\n",
        "        * Always ignore warnings that are generic, false positives, or do not highlight a tangible defect.\n",
        "        * When referencing a valid warning's substance, omit tool or rule names.\n",
        "    * **Output Standards:** Comments must be polite, professional, precise, actionable, and formatted in Markdown.\n",
        "\n",
        "    **Evaluation Process:**\n",
        "\n",
        "    **A. If a Human Review Comment IS PROVIDED:**\n",
        "\n",
        "    1.  **Classify the Human Comment:**\n",
        "        * If it is clearly from the patch author or is an abstract question not highlighting a defect: Output `NotRelevant` and stop.\n",
        "        * If it appears to be genuine reviewer feedback about a potential defect: Proceed to step A.2.\n",
        "\n",
        "    2.  **Rewrite the Human Comment:**\n",
        "        * Refine the comment according to the **Output Standards** and **Defect-Centric** guideline.\n",
        "        * If the human comment mentions or could be supported by a static analysis warning, ensure this warning meets all criteria under **Guidelines for Static Analysis Warnings** before incorporating its essence.\n",
        "        * Output *only* your rewritten Markdown comment.\n",
        "\n",
        "    **B. If NO Human Review Comment IS PROVIDED:**\n",
        "\n",
        "    1.  **Conduct Your Own Review:**\n",
        "        * Examine the code patch, final patched code, and any static analysis warnings.\n",
        "        * Identify any **code defects** based on the **Core Objective** and **Guidelines for Static Analysis Warnings**.\n",
        "\n",
        "    2.  **Formulate Your Comment:**\n",
        "        * If you identify one or more actionable **code defects**: Write a single, consolidated professional Markdown review comment. You may use bullet points if addressing multiple related defects within this single comment.\n",
        "        * If no **code defects** are identified: Output `NoComment`.\n",
        "\n",
        "    **Allowed Outputs (Strictly one of the following for any given task):**\n",
        "    * `NotRelevant`\n",
        "    * `NoComment`\n",
        "    * A single Markdown-formatted review comment (no extra headings or explanations beyond the comment itself).\n",
        "\n",
        "    Do not output anything else.\n",
        "    \"\"\"\n",
        "\n",
        "    user_prompt_content = f\"\"\"Please generate an \"Enhanced Review Comment\" based on the following inputs:\n",
        "      ## Code Diff\n",
        "      {patch}\n",
        "\n",
        "      ## Original Human Review\n",
        "      {real_human_review}\n",
        "\n",
        "      ## PMD Warnings\n",
        "      {pmd_warnings}\n",
        "\n",
        "      ## Patched Code\n",
        "      {patched_code}\n",
        "\n",
        "      Response:\n",
        "      \"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt_teacher},\n",
        "        {\"role\": \"user\", \"content\": user_prompt_content}\n",
        "    ]\n",
        "    return messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQCyP3pZa6jP"
      },
      "source": [
        "API helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EbBNm38BakxA"
      },
      "outputs": [],
      "source": [
        "def call_deepseek_api_sync(\n",
        "    messages: List[Dict[str, str]],\n",
        "    model_id: str = DEEPSEEK_MODEL_ID,\n",
        "    api_key: str = DEEPSEEK_API_KEY,\n",
        "    api_url: str = DEEPSEEK_API_URL,\n",
        "    timeout: int = 180,\n",
        ") -> Optional[Dict]:\n",
        "    \"\"\"Synchronous DeepSeek completion.\"\"\"\n",
        "    if not api_key:\n",
        "        raise ValueError(\"DEEPSEEK_API_KEY is not set.\")\n",
        "\n",
        "    headers = {\"Content-Type\": \"application/json\",\n",
        "               \"Authorization\": f\"Bearer {api_key}\"}\n",
        "\n",
        "    payload = {\n",
        "        \"model\": model_id,\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 1500,\n",
        "        \"temperature\": 0.3,\n",
        "        \"top_p\": 0.95,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(api_url, headers=headers, json=payload, timeout=timeout)\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    except requests.exceptions.Timeout:\n",
        "        print(f\"Timeout after {timeout}s.\")\n",
        "    except requests.exceptions.RequestException as err:\n",
        "        print(f\"Request error: {err}\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPzYeqSsa9IU"
      },
      "source": [
        "Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "45ks9cVYazmW"
      },
      "outputs": [],
      "source": [
        "def number_lines(code: str) -> str:\n",
        "    \"\"\"Return code with 1-based line numbers prefixed.\"\"\"\n",
        "    lines = code.splitlines()\n",
        "    width = len(str(len(lines)))\n",
        "    return \"\\n\".join(f\"{str(i+1).rjust(width)} | {line}\" for i, line in enumerate(lines))\n",
        "\n",
        "def print_samples(samples: List[Dict], start: int = 0, end: int = 2) -> None:\n",
        "    \"\"\"Pretty-print a slice of sample entries.\"\"\"\n",
        "    for idx in range(start, end + 1):\n",
        "        s = samples[idx]\n",
        "        print(f\"\\n— Sample {idx+1} (ID: {s.get('id')}) —\")\n",
        "        print(\"Patch:\\n\", s.get(\"patch\", \"\").strip())\n",
        "        print(\"\\nPatched Code:\\n\", s.get(\"code\", \"\").strip())\n",
        "        print(\"\\nPMD Warnings:\\n\", s.get(\"pmdWarnings\", \"\"))\n",
        "        print(\"\\nReal Review:\\n\", s.get(\"realReview\", \"\").strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZE6iuKvbBRD"
      },
      "source": [
        "JSONL helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "A64Q4sYpbCGu"
      },
      "outputs": [],
      "source": [
        "def load_existing_results(path: str) -> Dict[str, Dict]:\n",
        "    if not os.path.exists(path):\n",
        "        return {}\n",
        "    with open(path, encoding=\"utf-8\") as f:\n",
        "        return {json.loads(line)[\"id\"]: json.loads(line) for line in f if line.strip()}\n",
        "\n",
        "def save_result_to_jsonl(path: str, record: Dict) -> None:\n",
        "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-XXcWyOJcQ2F"
      },
      "outputs": [],
      "source": [
        "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "parsed_samples = [json.loads(line) for line in lines]\n",
        "\n",
        "new_samples = []\n",
        "for i, entry in enumerate(parsed_samples[:3]):\n",
        "    new_sample = {\n",
        "        \"id\": entry.get(\"id\"),\n",
        "        \"patch\": entry.get(\"patch\"),\n",
        "        \"code\": entry.get(\"code\"),\n",
        "        \"pmdWarnings\": entry.get(\"pmdWarnings\"),\n",
        "        \"realReview\": entry.get(\"realReview\")\n",
        "    }\n",
        "    new_samples.append(new_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hynYj9-Ecj8X"
      },
      "outputs": [],
      "source": [
        "print_samples(new_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmQJ_5lcbEcf"
      },
      "source": [
        "Sample processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hM8I8c6cbIPE"
      },
      "outputs": [],
      "source": [
        "def process_sample(sample: Dict) -> Optional[Dict]:\n",
        "    real_review   = sample[\"realReview\"].strip() or \"Comment not provided\"\n",
        "    pmd_warnings  = (\"\\n\".join(sample[\"pmdWarnings\"])\n",
        "                     if isinstance(sample[\"pmdWarnings\"], list)\n",
        "                     else sample[\"pmdWarnings\"]).strip() or \"No warnings\"\n",
        "\n",
        "    messages = construct_teacher_prompt_messages(\n",
        "        sample[\"patch\"],\n",
        "        real_review,\n",
        "        pmd_warnings,\n",
        "        number_lines(sample[\"code\"]),\n",
        "    )\n",
        "\n",
        "    response = call_deepseek_api_sync(messages)\n",
        "    if not response:\n",
        "        return None\n",
        "\n",
        "    review = (response.get(\"choices\", [{}])[0]\n",
        "              .get(\"message\", {})\n",
        "              .get(\"content\", \"\")\n",
        "              .strip())\n",
        "\n",
        "    sample[\"teacherReview\"] = review or \"No review generated\"\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC-O-CrVbM3U"
      },
      "source": [
        "Main pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_66nzILdNcz"
      },
      "outputs": [],
      "source": [
        "# 1. Load dataset\n",
        "with open(DATA_PATH, encoding=\"utf-8\") as f:\n",
        "    parsed_samples = [json.loads(line) for line in f]\n",
        "\n",
        "samples = [\n",
        "    {\n",
        "        \"id\": s.get(\"id\"),\n",
        "        \"patch\": s.get(\"patch\"),\n",
        "        \"code\": s.get(\"code\"),\n",
        "        \"pmdWarnings\": s.get(\"pmdWarnings\"),\n",
        "        \"realReview\": s.get(\"realReview\"),\n",
        "    }\n",
        "    for s in parsed_samples\n",
        "]\n",
        "\n",
        "# 2. Skip already processed IDs\n",
        "existing = load_existing_results(OUTPUT_PATH)\n",
        "todo     = [s for s in samples if s[\"id\"] not in existing]\n",
        "\n",
        "print(f\"Unprocessed samples: {len(todo)}\")\n",
        "\n",
        "# 3. Run enrichment in parallel\n",
        "processed = 0\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=1) as pool:\n",
        "    futures = {pool.submit(process_sample, s): s[\"id\"] for s in todo}\n",
        "    for fut in concurrent.futures.as_completed(futures):\n",
        "        result = fut.result()\n",
        "        if result and \"teacherReview\" in result:\n",
        "            save_result_to_jsonl(OUTPUT_PATH, result)\n",
        "            processed += 1\n",
        "            print(f\"✓ [{processed}/{len(todo)}] Saved: {result['id']}\")\n",
        "        else:\n",
        "            print(f\"✗ Failed: {futures[fut]}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
