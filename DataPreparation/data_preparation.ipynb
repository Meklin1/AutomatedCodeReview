{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Original dataset preparation and processing with PMD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXYrJmQciB3d"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import io\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import subprocess\n",
        "import threading\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Set\n",
        "import javalang\n",
        "from unidiff import PatchSet\n",
        "import xml.etree.ElementTree as ET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUlHIkELfwJM"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(r\"CodeReviewer\")\n",
        "\n",
        "RAW_DIR      = BASE_DIR / \"Dataset\" / \"OriginalDataset\"\n",
        "TEMP_DIR     = BASE_DIR / \"DataPreparation\" / \"Temp\"\n",
        "TRAIN_RAW    = RAW_DIR / \"cls-train-chunk-0.jsonl\"\n",
        "TEST_RAW     = RAW_DIR / \"cls-test.jsonl\"\n",
        "VALID_RAW     = RAW_DIR / \"cls-valid.jsonl\"\n",
        "\n",
        "MAX_CODE_LEN = 15_000    # skip very large files\n",
        "PMD_EXE      = \"pmd.bat\"\n",
        "PMD_RULESETS = \",\".join([\n",
        "    \"category/java/errorprone.xml\",\n",
        "    \"category/java/multithreading.xml\",\n",
        "    \"category/java/performance.xml\",\n",
        "    \"category/java/codestyle.xml\",\n",
        "    \"category/java/bestpractices.xml\",\n",
        "    \"category/java/design.xml\",\n",
        "    \"category/java/security.xml\",\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeAxfw0IgCLn"
      },
      "source": [
        " Helpers: I/O utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywFMrfnuf-XS"
      },
      "outputs": [],
      "source": [
        "def ensure_dir(p: Path | str) -> Path:\n",
        "    p = Path(p)\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "    return p\n",
        "\n",
        "def write_jsonl(out_path: Path, record: dict) -> None:\n",
        "    with out_path.open(\"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgBOX04tgLcA"
      },
      "source": [
        " Stage A – Filter valid Java entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQZDlKxOgGSm"
      },
      "outputs": [],
      "source": [
        "def filter_java_entries(\n",
        "    input_path: Path,\n",
        "    output_path: Path,\n",
        ") -> None:\n",
        "    total = sum(1 for line in input_path.open(encoding=\"utf-8\") if line.strip())\n",
        "    checked = valid = 0\n",
        "\n",
        "    with input_path.open(encoding=\"utf-8\") as inp, \\\n",
        "         output_path.open(\"w\", encoding=\"utf-8\") as out:\n",
        "\n",
        "        for raw in inp:\n",
        "            if not raw.strip():\n",
        "                continue\n",
        "            checked += 1\n",
        "            if checked % 500 == 0 or checked == total:\n",
        "                print(f\"Filter progress: {checked}/{total}\", end=\"\\r\")\n",
        "\n",
        "            try:\n",
        "                data = json.loads(raw)\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "\n",
        "            lang, code = data.get(\"lang\"), data.get(\"oldf\")\n",
        "            if not code:\n",
        "                continue\n",
        "\n",
        "            if lang == \"java\":\n",
        "                out.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
        "                valid += 1\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                javalang.parse.parse(code)\n",
        "            except (javalang.parser.JavaSyntaxError,\n",
        "                    javalang.tokenizer.LexerError,\n",
        "                    IndexError,\n",
        "                    StopIteration):\n",
        "                continue\n",
        "\n",
        "            out.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
        "            valid += 1\n",
        "\n",
        "    print(f\"\\n✅ Saved {valid} valid Java entries → {output_path.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRnHOCu9gTvW"
      },
      "source": [
        " Stage B – Apply unified-diff patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALgCo_VXgRmP"
      },
      "outputs": [],
      "source": [
        "def apply_patch(original: str, patch_text: str) -> str:\n",
        "    if not patch_text.startswith(\"---\"):\n",
        "        patch_text = \"--- a/file.java\\n+++ b/file.java\\n\" + patch_text\n",
        "\n",
        "    patch = PatchSet(io.StringIO(patch_text))\n",
        "    lines = original.splitlines()\n",
        "    patched = lines.copy()\n",
        "\n",
        "    for pf in patch:\n",
        "        for hunk in reversed(pf):\n",
        "            start = hunk.source_start - 1\n",
        "            end   = start + hunk.source_length\n",
        "            del patched[start:end]\n",
        "\n",
        "            new_lines = [\n",
        "                l.value.rstrip(\"\\n\") for l in hunk\n",
        "                if l.is_added or l.is_context\n",
        "            ]\n",
        "            for l in reversed(new_lines):\n",
        "                patched.insert(start, l)\n",
        "\n",
        "    return \"\\n\".join(patched)\n",
        "\n",
        "def add_patched_code(\n",
        "    input_path: Path,\n",
        "    output_path: Path,\n",
        "    max_len: int = MAX_CODE_LEN,\n",
        ") -> None:\n",
        "    ensure_dir(output_path.parent)\n",
        "    kept = skipped = 0\n",
        "\n",
        "    with input_path.open(encoding=\"utf-8\") as inp, \\\n",
        "         output_path.open(\"w\", encoding=\"utf-8\") as out:\n",
        "\n",
        "        for raw in inp:\n",
        "            data = json.loads(raw)\n",
        "            if data.get(\"lang\") != \"java\":\n",
        "                continue\n",
        "\n",
        "            patched = apply_patch(data.get(\"oldf\", \"\"), data.get(\"patch\", \"\"))\n",
        "            if len(patched) > max_len:\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            data[\"code\"] = patched\n",
        "            out.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
        "            kept += 1\n",
        "\n",
        "    print(f\"✅ Patched {kept} entries  |  Skipped (too long): {skipped}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu3cwVLNgdZD"
      },
      "source": [
        "Stage C – Basic dataset stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz8R7AHYgc_2"
      },
      "outputs": [],
      "source": [
        "def show_longest_entry(jsonl_path: Path) -> None:\n",
        "    longest, max_len = None, 0\n",
        "    for raw in jsonl_path.open(encoding=\"utf-8\"):\n",
        "        data = json.loads(raw)\n",
        "        code_len = len(data.get(\"code\", \"\"))\n",
        "        if code_len > max_len:\n",
        "            max_len, longest = code_len, data\n",
        "    if longest:\n",
        "        print(f\"▶ Longest ID: {longest['id']}  |  {max_len} chars\")\n",
        "        print(f\"Message: {longest.get('msg')}\\n\")\n",
        "        print(longest[\"code\"][:2000], \"...\" if max_len > 2000 else \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU0g-3zagiUp"
      },
      "source": [
        " Stage D – Run PMD in parallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeMoMDdBgk93"
      },
      "outputs": [],
      "source": [
        "def run_pmd(java_path: Path, report_path: Path) -> int:\n",
        "    cmd = [\n",
        "        PMD_EXE, \"check\",\n",
        "        \"-d\", str(java_path),\n",
        "        \"-R\", PMD_RULESETS,\n",
        "        \"-f\", \"xml\",\n",
        "        \"-r\", str(report_path),\n",
        "        \"--minimum-priority\", \"3\",\n",
        "    ]\n",
        "    proc = subprocess.run(cmd,\n",
        "                          stdout=subprocess.DEVNULL,\n",
        "                          stderr=subprocess.PIPE,\n",
        "                          shell=False)\n",
        "    # PMD returns 4 when only low-priority rules fail, treat as success\n",
        "    return 0 if proc.returncode in (0, 4) else proc.returncode\n",
        "\n",
        "def pmd_batch(mode: str, jsonl_path: Path, work_dir: Path) -> None:\n",
        "    mode = mode.capitalize()\n",
        "    code_dir    = ensure_dir(work_dir / mode / \"ExtractedCode\")\n",
        "    reports_dir = ensure_dir(work_dir / mode / \"Reports\")\n",
        "    failed_dir  = ensure_dir(reports_dir / \"Failed\")\n",
        "\n",
        "    stats = {\"total\": 0, \"processed\": 0, \"errors\": 0}\n",
        "    lock  = threading.Lock()\n",
        "    futures = []\n",
        "\n",
        "    def _task(entry: dict):\n",
        "        nonlocal stats\n",
        "        eid, code = entry[\"id\"], entry[\"code\"]\n",
        "        java_f = code_dir / f\"{eid}.java\"\n",
        "        report = reports_dir / f\"{eid}.xml\"\n",
        "\n",
        "        java_f.write_text(code, encoding=\"utf-8\")\n",
        "        rc = run_pmd(java_f, report)\n",
        "        with lock:\n",
        "            stats[\"processed\"] += 1 if rc == 0 else 0\n",
        "            stats[\"errors\"]    += 0 if rc == 0 else 1\n",
        "        if rc:\n",
        "            shutil.copy(java_f, failed_dir / java_f.name)\n",
        "        return eid, rc\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=os.cpu_count()*4) as ex, \\\n",
        "         jsonl_path.open(encoding=\"utf-8\") as inp:\n",
        "\n",
        "        for raw in inp:\n",
        "            entry = json.loads(raw)\n",
        "            stats[\"total\"] += 1\n",
        "            futures.append(ex.submit(_task, entry))\n",
        "\n",
        "        for f in as_completed(futures):\n",
        "            eid, rc = f.result()\n",
        "            status = \"✅\" if rc == 0 else \"❌\"\n",
        "            with lock:\n",
        "                done = stats[\"processed\"] + stats[\"errors\"]\n",
        "                print(f\"{status} {eid} ({done}/{stats['total']})\", end=\"\\r\")\n",
        "\n",
        "    print(f\"\\n{mode} PMD: {stats}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I22A4IDgvRw"
      },
      "source": [
        " Stage E – Attach PMD warnings to diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JRczo76gxx0"
      },
      "outputs": [],
      "source": [
        "HUNK_HEADER = re.compile(r\"^@@ -\\d+(?:,\\d+)? \\+(\\d+)(?:,(\\d+))? @@\")\n",
        "\n",
        "def changed_lines(patch: str) -> Set[int]:\n",
        "    changed, new_line = set(), None\n",
        "    for l in patch.splitlines():\n",
        "        m = HUNK_HEADER.match(l)\n",
        "        if m:\n",
        "            new_line = int(m.group(1))\n",
        "            continue\n",
        "        if new_line is None or l.startswith((\"---\", \"+++\")):\n",
        "            continue\n",
        "        if l.startswith('+'):\n",
        "            changed.add(new_line)\n",
        "            new_line += 1\n",
        "        elif l.startswith('-'):\n",
        "            continue\n",
        "        else:\n",
        "            new_line += 1\n",
        "    return changed\n",
        "\n",
        "def relevant_warnings(xml_path: Path, changed: Set[int]) -> List[str]:\n",
        "    if not xml_path.is_file():\n",
        "        return []\n",
        "    ns = {\"p\": \"http://pmd.sourceforge.net/report/2.0.0\"}\n",
        "    try:\n",
        "        root = ET.parse(xml_path).getroot()\n",
        "    except ET.ParseError:\n",
        "        return []\n",
        "\n",
        "    warnings: List[str] = []\n",
        "    for v in root.findall(\".//p:violation\", ns):\n",
        "        beg, end = int(v.attrib[\"beginline\"]), int(v.attrib[\"endline\"])\n",
        "        if any(l in changed for l in range(beg, end+1)):\n",
        "            txt = (v.text or \"\").strip()\n",
        "            warnings.append(f\"{beg}-{end} | {v.attrib['rule']}: {txt}\")\n",
        "    return warnings\n",
        "\n",
        "def augment_with_pmd(mode: str, work_dir: Path) -> None:\n",
        "    mode = mode.capitalize()\n",
        "    dataset   = work_dir / mode / f\"{mode.lower()}-java-with-code.jsonl\"\n",
        "    reports   = work_dir / mode / \"Reports\"\n",
        "    out_path  = work_dir / mode / f\"{mode.lower()}-java-with-code-with-pmd.jsonl\"\n",
        "\n",
        "    total = 0\n",
        "    with dataset.open(encoding=\"utf-8\") as inp, out_path.open(\"w\", encoding=\"utf-8\") as out:\n",
        "        for raw in inp:\n",
        "            entry = json.loads(raw)\n",
        "            diff_lines = changed_lines(entry.get(\"patch\", \"\"))\n",
        "            xml_file   = reports / f\"{entry['id']}.xml\"\n",
        "            warnings   = relevant_warnings(xml_file, diff_lines)\n",
        "\n",
        "            out_rec = {\n",
        "                \"id\":          entry[\"id\"],\n",
        "                \"realReview\":  entry.get(\"msg\", \"\"),\n",
        "                \"pmdWarnings\": warnings,\n",
        "                \"patch\":       entry[\"patch\"],\n",
        "                \"code\":        entry[\"code\"],\n",
        "            }\n",
        "            out.write(json.dumps(out_rec, ensure_ascii=False) + \"\\n\")\n",
        "            total += 1\n",
        "\n",
        "    print(f\"✅ {mode}: PMD-augmented file → {out_path.name}  ({total} entries)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RPMMDrmg-kY"
      },
      "source": [
        " Driver functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYGY9T_ag8c9"
      },
      "outputs": [],
      "source": [
        "def prepare_datasets():\n",
        "    # Stage A\n",
        "    java_train = TEMP_DIR / \"Train\" / \"train-java.jsonl\"\n",
        "    java_test  = TEMP_DIR / \"Test\"  / \"test-java.jsonl\"\n",
        "    java_valid  = TEMP_DIR / \"Valid\"  / \"valid-java.jsonl\"\n",
        "    ensure_dir(java_train.parent)\n",
        "    filter_java_entries(TRAIN_RAW, java_train)\n",
        "    filter_java_entries(TEST_RAW,  java_test)\n",
        "    filter_java_entries(VALID_RAW,  java_valid)\n",
        "\n",
        "    # Stage B\n",
        "    patched_train = TEMP_DIR / \"Train\" / \"train-java-with-code.jsonl\"\n",
        "    patched_test  = TEMP_DIR / \"Test\"  / \"test-java-with-code.jsonl\"\n",
        "    patched_valid  = TEMP_DIR / \"Valid\"  / \"valid-java-with-code.jsonl\"\n",
        "    add_patched_code(java_train, patched_train)\n",
        "    add_patched_code(java_test,  patched_test)\n",
        "    add_patched_code(java_valid,  patched_valid)\n",
        "\n",
        "    # Optional quick stats\n",
        "    show_longest_entry(patched_train)\n",
        "\n",
        "    # Stage D\n",
        "    pmd_batch(\"Train\", patched_train, TEMP_DIR)\n",
        "    pmd_batch(\"Test\",  patched_test,  TEMP_DIR)\n",
        "    pmd_batch(\"Valid\", patched_valid, TEMP_DIR)\n",
        "\n",
        "    # Stage E\n",
        "    augment_with_pmd(\"Train\", TEMP_DIR)\n",
        "    augment_with_pmd(\"Test\",  TEMP_DIR)\n",
        "    augment_with_pmd(\"Valid\",  TEMP_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MjuUtXwhin_"
      },
      "outputs": [],
      "source": [
        "prepare_datasets()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
